{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/andrew/DATA/git_repos/CAMP-RT/PYTHON/preprocessing.py:11: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from analysis import *\n",
    "from collections import namedtuple\n",
    "import Metrics\n",
    "from PatientSet import PatientSet\n",
    "from Constants import Constants\n",
    "from Clustering import *\n",
    "import re\n",
    "\n",
    "#sklearn dependencies\n",
    "from sklearn.metrics import roc_auc_score, adjusted_rand_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "\n",
    "#we get like a million deprication errors for some reason with the external libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting parameter\n",
    "SMALL_SIZE = 18\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 24\n",
    "FIG_SIZE = (20,15)\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc('figure', figsize=FIG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/andrew/DATA/git_repos/CAMP-RT/PYTHON/Patient.py:360: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mean_tumor_distances /= tumor_volume\n",
      "/media/andrew/DATA/git_repos/CAMP-RT/PYTHON/Patient.py:361: RuntimeWarning: invalid value encountered in true_divide\n",
      "  tumor_position /= tumor_volume\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error reading tumor volume for  10091\n",
      "error reading tumor volume for  10148\n",
      "WARNING:tensorflow:From /home/evl/andrew/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evl/andrew/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evl/andrew/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evl/andrew/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evl/andrew/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "\n",
      "patient data loaded...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load in the patientset object that has all the patient info\n",
    "db = PatientSet()\n",
    "\n",
    "#add a bunch of features to the object that we'll want to try\n",
    "#so we can use the db.to_dataframe function to get them all in a nice dataframe with one-hot encoding and labels automatically\n",
    "db.t_volumes = np.array([np.sum([g.volume for g in gtvs]) for gtvs in db.gtvs]).reshape(-1,1)\n",
    "db.bilateral = db.lateralities == 'B'\n",
    "db.total_volumes = db.volumes.sum(axis = 1)\n",
    "db.toxicity = db.feeding_tubes + db.aspiration > 0\n",
    "db.tsimdoses = tsim_prediction(db)\n",
    "db.neck_width = np.linalg.norm(db.centroids[:,Constants.organ_list.index('Lt_Sternocleidomastoid_M'),:] - db.centroids[:,Constants.organ_list.index('Rt_Sternocleidomastoid_M'), :], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'clusterer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3ae417b0e1d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m cluster_feature_selector = FeatureClusterSelector(\n\u001b[1;32m     32\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     clusterer = selection_clusterer)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mlg_feature_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureSelector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'clusterer'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from Clustering import *\n",
    "\n",
    "#parameters for the experiments\n",
    "toxicities_to_test = ['toxicity']\n",
    "\n",
    "#features to test the feature selection on.  should be fields in the patientset we have\n",
    "#we don't cluster on these\n",
    "unclusterable_features = ['t_volumes', 'bilateral', 'total_volumes','neck_width']\n",
    "#we cluster on these (each individually) if feature_clustering is defined,\n",
    "clusterable_features = ['tumor_distances', 'volumes']\n",
    "\n",
    "#features specifically for feature selection vs actually using.  Should either be\n",
    "#some combo of actual and predicted dose for this\n",
    "true_features = ['doses']\n",
    "predicted_features = ['tsimdoses']\n",
    "\n",
    "#number of times to resample and doing feature selection\n",
    "#if n = 1, just use the first result\n",
    "n_samples = 300\n",
    "\n",
    "df_rescale = Metrics.normalize\n",
    "\n",
    "#put some bounds on the features to subset\n",
    "min_features = 2\n",
    "\n",
    "#for now just constrain it to one cluster\n",
    "n_clusters = 2\n",
    "selection_clusterer  = FClusterer(n_clusters)\n",
    "cluster_feature_selector = FeatureClusterSelector(\n",
    "    n_samples = n_samples,\n",
    "    model = selection_clusterer)\n",
    "lg_feature_selector = FeatureSelector(n_samples = n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, predicted = get_train_test_datasets(db, \n",
    "                                      unclusterable_features, \n",
    "                                      clusterable_features, \n",
    "                                      true_features, \n",
    "                                      predicted_features)\n",
    "if df_rescale is not None:\n",
    "    true = df_rescale(true)\n",
    "    predicted = df_rescale(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_importances = cluster_feature_selector.get_importances(predicted, db.toxicity, as_df = True)\n",
    "cluster_importances.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_importances = lg_feature_selector.get_importances(predicted, db.toxicity, as_df = True)\n",
    "lg_importances.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_n_importances = lambda x, n: x.mean().sort_values(ascending = False).iloc[0:n]\n",
    "def plot_n_importances(x, n):\n",
    "    x = x.reindex(x.mean().sort_values(ascending=False).index, axis = 'columns')\n",
    "    x = x.iloc[:,0:n]\n",
    "    xrange = [x.mean().values.min()*.99, x.mean().values.max()*1.01]\n",
    "    x.mean().plot.barh(**{'xerr': x.std().values/np.sqrt(n_samples), 'xlim': xrange})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_importances(lg_importances,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cluster_importances = cluster_importances = cluster_feature_selector.get_importances(true, db.toxicity, as_df = True)\n",
    "true_cluster_importances.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_importances(true_cluster_importances, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_lg_importances8 = lg_feature_selector.get_importances(true, db.toxicity, as_df = True)\n",
    "true_lg_importances.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_n_importances(true_lg_importances, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load in the selected features from the clustering notebook\n",
    "selected_features = pd.read_csv('data/clustering_results/metaClusteringBootstrapped300.csv',index_col=0)\n",
    "cluster_labels = selected_features.cluster_labels\n",
    "selected_features = selected_features.drop('cluster_labels', axis = 1)\n",
    "selected_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the relative loss of accuracy from dropping each of the variables in the selected features\n",
    "scorer = FeatureClusterSelector(clusterer = copy.copy(selection_clusterer))\n",
    "scores = {f: [] for f in selected_features.columns}\n",
    "scores['baseline'] = []\n",
    "for n in range(n_samples):\n",
    "    if n_samples > 1:\n",
    "        xtemp, ytemp = resample(selected_features, db.toxicity)\n",
    "    else:\n",
    "        xtemp, ytemp = selected_features, db.toxicity\n",
    "    base_score = scorer.bootstrap_score(xtemp, ytemp).mean()\n",
    "    scores['baseline'].append(base_score)\n",
    "    for feature in  selected_features.columns:\n",
    "        xtemp = selected_features.drop(feature, axis = 1)\n",
    "        new_score = scorer.bootstrap_score(xtemp, db.toxicity).mean()\n",
    "        scores[feature].append(base_score-new_score)\n",
    "scores = pd.DataFrame(scores)\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the scores (drop in clustering correlation) to an actual importance\n",
    "fscores = scores.drop('baseline', axis = 1).apply(lambda x: 1/np.log(np.abs(1/x))*np.sign(x))\n",
    "yerr = fscores.std()/np.sqrt(n_samples) if n_samples > 1 else np.zeros((fscores.shape[1],))\n",
    "yrange = [fscores.mean().values.min()*.9, fscores.mean().values.max()*1.1]\n",
    "(fscores.mean()).plot.bar(rot = 45, **{'ylim': yrange,'yerr': yerr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcounts = np.arange(1, int(selected_features.shape[0]/2))\n",
    "n_subsamples = selected_features.shape[0]\n",
    "sensitivity_report = np.zeros((n_subsamples, len(pcounts)))\n",
    "feature_df = selected_features.copy()\n",
    "feature_df['toxicity'] = db.toxicity\n",
    "for p in pcounts:\n",
    "    for n in range(n_subsamples):\n",
    "        data_subset = feature_df.sample(n=int(selected_features.shape[0] - p),\n",
    "                                          replace = False,\n",
    "                                          random_state = n)\n",
    "        tox_subset = data_subset['toxicity'].values\n",
    "        clusters = selection_clusterer.fit_predict(data_subset.drop(['toxicity'],axis=1).values)\n",
    "        sensitivity_report[n, p] = fisher_exact_test(tox_subset, clusters)\n",
    "pd.DataFrame(sensitivity_report).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.toxicity\n",
    "In [ ]:\n",
    "￼\n",
    "​\n",
    "In [ ]:\n",
    "￼\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
